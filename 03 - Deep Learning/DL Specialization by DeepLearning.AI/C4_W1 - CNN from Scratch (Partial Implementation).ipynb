{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b007bf9-5739-4c81-aed3-2513c3ded80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68f48f-6ac1-4d58-8f5d-b7dcbf1af5ba",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa71817b-30a2-49e1-946e-5d6cf2720de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(X, n_pads):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    n_pads -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_padded -- padded image of shape (m, n_H + 2 * n_pads, n_W + 2 * n_pads, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    X_padded = np.pad(X, ((0,0), (n_pads,n_pads), (n_pads,n_pads), (0,0)), mode='constant', constant_values = (0,0))\n",
    "    return X_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb864039-bfbd-4f43-a211-c43ba55ff5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (1, 3, 3, 3)\n",
      "x_padded.shape = (1, 9, 9, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.rand(1, 3, 3, 3)\n",
    "x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "x_padded = pad_with_zeros(x, n_pads=3)\n",
    "\n",
    "print('x.shape =', x.shape)\n",
    "print('x_padded.shape =', x_padded.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 8))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes\n",
    "\n",
    "for i in range(3):\n",
    "    axes[i*2].set_title(f'x - channel {i+1}')\n",
    "    axes[i*2].imshow(x[0, :, :, i], cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    axes[i*2+1].set_title(f'x_pad - channel {i+1}')\n",
    "    axes[i*2+1].imshow(x_padded[0, :, :, i], cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9ac4a-fdc1-4e1f-aedb-da03e6dac19b",
   "metadata": {},
   "source": [
    "# Forward Pass of Conv_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f295437e-3333-4a55-b311-d801466df3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(a_sliced_prev, w, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_sliced_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    w -- Weights in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    z = np.sum(a_sliced_prev * w) + b.item()  # Extract the scalar value from the array b\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a8c130-a283-4689-bbac-6d169419a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "w = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "z = convolute(a_slice_prev, w, b)\n",
    "print(\"Z =\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12548b-a5d8-4705-bb7c-c2caef08140b",
   "metadata": {},
   "source": [
    "The formulas relating the output shape of the convolution to the input shape are:\n",
    "    \n",
    "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
    "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
    "$$n_C = \\text{number of filters used in the convolution}$$\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "For this exercise, don't worry about vectorization! Just implement everything with for-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5793c2-08c6-44b5-aa76-a707a2bab437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_conv(A_prev, W, B, padding, strides):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- output of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f_H, f_W, n_C_prev, n_C)\n",
    "    B -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    padding -- int, the amount of zero-padding to add around the border\n",
    "    strides -- tuple of two ints, (stride_h, stride_w), the strides for height and width\n",
    "    \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the backward_conv() function\n",
    "    \"\"\"\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    f_H, f_W, _, n_C = W.shape\n",
    "    stride_H, stride_W = strides\n",
    "    \n",
    "    n_H = int((n_H_prev - f_H + 2*padding) / stride_H) + 1\n",
    "    n_W = int((n_W_prev - f_W + 2*padding) / stride_W) + 1\n",
    "\n",
    "    A_prev_padded = pad_with_zeros(A_prev, n_pads=padding)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev = A_prev_padded[i]  # Take 1 sample\n",
    "        \n",
    "        for h in range(n_H):  # Loop over output height\n",
    "            start_H = h * stride_H\n",
    "            end_H = start_H + f_H\n",
    "\n",
    "            for w in range(n_W):  # Loop over output width\n",
    "                start_W = w * stride_W\n",
    "                end_W = start_W + f_W\n",
    "\n",
    "                for c in range(n_C):  # Loop over the number of channels\n",
    "                    a_sliced_prev = a_prev[start_H:end_H, start_W:end_W, :]  # Take a slice across 3D of 1 sample\n",
    "                \n",
    "                    Z[i, h, w, c] = convolute(a_sliced_prev, W[..., c], B[..., c])\n",
    "\n",
    "    cache_conv = (A_prev, W, B, padding, strides)\n",
    "    return Z, cache_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47970005-85a2-445b-8ad6-d6d9f7c74a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z.shape = (2, 3, 4, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2.17796037,  8.07171329, -0.5772704 ,  3.36286738,  4.48113645,\n",
       "        -2.89198428, 10.99288867,  3.03171932]),\n",
       " array([-1.1191154 ,  1.9560789 , -0.3264995 , -1.34267579]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "B = np.random.randn(1, 1, 1, 8)\n",
    "\n",
    "padding = 1\n",
    "strides = (2,2)\n",
    "\n",
    "Z, cache_conv = forward_conv(A_prev, W, B, padding, strides)\n",
    "print('Z.shape =', Z.shape)\n",
    "Z[0, 2, 1], cache_conv[0][1][2][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683cbabd-da3f-4131-87ab-0f866c3742dc",
   "metadata": {},
   "source": [
    "# Forward Pass of Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e058a-fda6-46f5-a08e-0e73bd380a0a",
   "metadata": {},
   "source": [
    "As there's no padding, the formulas binding the output shape of the pooling to the input shape is:\n",
    "\n",
    "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - p}{stride} \\Bigr\\rfloor +1$$\n",
    "\n",
    "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - p}{stride} \\Bigr\\rfloor +1$$\n",
    "\n",
    "$$n_C = n_{C_{prev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53c1269-3a96-4870-8b14-9486f710ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pool(A_prev, pool_size, strides, mode='max'):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    pool_size -- tuple of two ints, (f_H, f_W), size of the pooling window\n",
    "    strides -- tuple of two ints, (stride_H, stride_W), the stride for height and width\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pooling layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache_pool -- cache of values needed for the backward pass of the pooling layer, contains the layer's input and hyperparameters\n",
    "    \"\"\"\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    p_H, p_W = pool_size\n",
    "    stride_H, stride_W = strides\n",
    "\n",
    "    n_H = int((n_H_prev - p_H) / stride_H) + 1\n",
    "    n_W = int((n_W_prev - p_W) / stride_W) + 1\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i]\n",
    "\n",
    "        for h in range(n_H):\n",
    "            start_H = h * stride_H\n",
    "            end_H = start_H + p_H\n",
    "\n",
    "            for w in range(n_W):\n",
    "                start_W = w * stride_W\n",
    "                end_W = start_W + p_W\n",
    "\n",
    "                for c in range(n_C):\n",
    "                    a_sliced_prev = a_prev[start_H:end_H, start_W:end_W, c]  # Take a slice of 1 channel of 1 sample\n",
    "              \n",
    "                    if mode == 'max':\n",
    "                        A[i, h, w, c] = np.max(a_sliced_prev)\n",
    "                    elif mode == 'average':\n",
    "                        A[i, h, w, c] = np.mean(a_sliced_prev)\n",
    "\n",
    "    cache_pool = (A_prev, pool_size, strides)\n",
    "    return A, cache_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90e5234-4f0b-4f41-9b8c-1a785ed8c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_max.shape = (2, 3, 3, 3)\n",
      "A_average.shape = (2, 3, 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.96710175, 0.84616065, 1.27375593],\n",
       "        [1.96710175, 0.84616065, 1.23616403],\n",
       "        [1.62765075, 1.12141771, 1.2245077 ]]),\n",
       " array([[ 0.44497696, -0.00261695, -0.31040307],\n",
       "        [ 0.50811474, -0.23493734, -0.23961183],\n",
       "        [ 0.11872677,  0.17255229, -0.22112197]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "\n",
    "pool_size = (3,3)\n",
    "strides = (1,1)\n",
    "\n",
    "A_max, _ = forward_pool(A_prev, pool_size, strides, mode='max')\n",
    "A_average, _ = forward_pool(A_prev, pool_size, strides, mode='average')\n",
    "print('A_max.shape =', A_max.shape)\n",
    "print('A_average.shape =', A_average.shape)\n",
    "A_max[1,1], A_average[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ed7901-b778-43af-8939-a1ce7a8d5eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_max.shape = (2, 2, 2, 3)\n",
      "A_average.shape = (2, 2, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[1.74481176, 0.90159072, 1.65980218],\n",
       "         [1.74481176, 1.6924546 , 1.65980218]],\n",
       " \n",
       "        [[1.13162939, 1.51981682, 2.18557541],\n",
       "         [1.13162939, 1.6924546 , 2.18557541]]]),\n",
       " array([[[-0.17313416,  0.32377198, -0.34317572],\n",
       "         [ 0.02030094,  0.14141479, -0.01231585]],\n",
       " \n",
       "        [[ 0.42944926,  0.08446996, -0.27290905],\n",
       "         [ 0.15077452,  0.28911175,  0.00123239]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: stride of 2\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "\n",
    "pool_size = (3,3)\n",
    "strides = (2,2)\n",
    "\n",
    "A_max, _ = forward_pool(A_prev, pool_size, strides, mode='max')\n",
    "A_average, _ = forward_pool(A_prev, pool_size, strides, mode='average')\n",
    "print('A_max.shape =', A_max.shape)\n",
    "print('A_average.shape =', A_average.shape)\n",
    "A_max[0], A_average[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a85dc-3ccf-46e5-9da0-15108374b508",
   "metadata": {},
   "source": [
    "**What you should remember**:\n",
    "\n",
    "* A convolution extracts features from an input image by taking the dot product between the input data and a 3D array of weights (the filter). \n",
    "* The 2D output of the convolution is called the feature map\n",
    "* A convolution layer is where the filter slides over the image and computes the dot product \n",
    "    * This transforms the input volume into an output volume of different size \n",
    "* Zero padding helps keep more information at the image borders, and is helpful for building deeper networks, because you can build a CONV layer without shrinking the height and width of the volumes\n",
    "* Pooling layers gradually reduce the height and width of the input by sliding a 2D window over each specified region, then summarizing the features in that region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417af27-2640-4bab-878d-dd6cc80f1c73",
   "metadata": {},
   "source": [
    "# Backpropagation of Conv_Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6394b-0cd0-4dbb-b96e-e68f7f90714f",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=z9hJzduHToc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b991f4-44fd-448b-889c-3d2772d48baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_conv(dZ, cache_conv):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost w.r.t the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache_conv -- Cache of values needed for backward propagation (A_prev, W, B, padding, strides)\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost w.r.t the input of the conv layer (A_prev), numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dW -- Gradient of the cost w.r.t the weights (W), numpy array of shape (f_H, f_W, n_C_prev, n_C)\n",
    "    dB -- Gradient of the cost w.r.t the biases (B), numpy array of shape (1, 1, 1, n_C)\n",
    "    \"\"\"    \n",
    "    A_prev, W, B, padding, strides = cache_conv\n",
    "    stride_H, stride_W = strides\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    f_H, f_W, _, n_C = W.shape\n",
    "    _, n_H, n_W, _ = dZ.shape\n",
    "\n",
    "    dA_prev = np.zeros(A_prev.shape)  # without padding\n",
    "    dW = np.zeros(W.shape)\n",
    "    dB = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    A_prev_padded = pad_with_zeros(A_prev, n_pads=padding)\n",
    "    dA_prev_padded = pad_with_zeros(dA_prev, n_pads=padding)\n",
    "\n",
    "    for i in range(m):\n",
    "        a_prev = A_prev_padded[i]\n",
    "        da_prev = dA_prev_padded[i]\n",
    "        \n",
    "        for h in range(n_H):\n",
    "            start_H = h * stride_H\n",
    "            end_H = start_H + f_H\n",
    "    \n",
    "            for w in range(n_W):\n",
    "                start_W = w * stride_W\n",
    "                end_W = start_W + f_W\n",
    "    \n",
    "                for c in range(n_C):\n",
    "                    a_sliced_prev = a_prev[start_H:end_H, start_W:end_W, :]\n",
    "\n",
    "                    da_prev[start_H:end_H, start_W:end_W, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:, :, :, c] += a_sliced_prev * dZ[i, h, w, c]\n",
    "                    dB[:, :, :, c] += dZ[i, h, w, c]\n",
    "\n",
    "        if padding != 0:  # remove padding\n",
    "            dA_prev[i, :, :, :] = da_prev[padding:-padding, padding:-padding, :]\n",
    "        else:\n",
    "            dA_prev[i, :, :, :] = da_prev\n",
    "        \n",
    "    return dA_prev, dW, dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4008a03-3e20-41ab-8f81-ecaa859fcfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev_mean = 1.4524377775388075\n",
      "dW_mean = 1.7269914583139097\n",
      "dB_mean = 7.839232564616838\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)\n",
    "W = np.random.randn(2, 2, 3, 8)\n",
    "B = np.random.randn(1, 1, 1, 8)\n",
    "\n",
    "padding = 2\n",
    "strides = (2,2)\n",
    "\n",
    "Z, cache_conv = forward_conv(A_prev, W, B, padding, strides)\n",
    "dA_prev, dW, dB = backward_conv(Z, cache_conv)\n",
    "\n",
    "print(\"dA_prev_mean =\", np.mean(dA_prev))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"dB_mean =\", np.mean(dB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8449017-140e-483d-b17a-3ae01340cb02",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            dA_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            1.45243777754\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            dW_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            1.72699145831\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            db_mean\n",
    "        </td>\n",
    "        <td>\n",
    "            7.83923256462\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba3661-b280-420a-9f73-793a076d7769",
   "metadata": {},
   "source": [
    "# Backpropagation of Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab219926-4062-4817-b186-a9a89c0272e1",
   "metadata": {},
   "source": [
    "### Helper Function for Max Pooling Backprop\n",
    "\n",
    "Before jumping into the backpropagation of the pooling layer, you are going to build a helper function which does the following: \n",
    "\n",
    "$$ A_{prev} = \\begin{bmatrix}\n",
    "1 && 3 \\\\\n",
    "4 && 2\n",
    "\\end{bmatrix} \\quad \\rightarrow \\quad mask\\_maxPool =\\begin{bmatrix}\n",
    "0 && 0 \\\\\n",
    "1 && 0\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "As you can see, this function creates a \"mask\" matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You'll see later that the backward pass for average pooling is similar to this, but uses a different mask.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642186a7-7740-4a21-b69d-ebfd443b6a11",
   "metadata": {},
   "source": [
    "### Helper Function for Average Pooling Backprop\n",
    "\n",
    "In max pooling, for each input window, all the \"influence\" on the output came from a single input value - the max value. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.\n",
    "\n",
    "For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you'll use for the backward pass will look like: \n",
    "$$ A_{prev} = \\begin{bmatrix}\n",
    "a && b \\\\\n",
    "c && d\n",
    "\\end{bmatrix} \\quad \\rightarrow \\quad mask\\_avgPool =\\begin{bmatrix}\n",
    "1/4 && 1/4 \\\\\n",
    "1/4 && 1/4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "This implies that each position in the `A_prev` matrix contributes equally to output because in the forward pass, we took an average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732bbf65-667b-42f3-8865-b910ddcdcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pool(dA, cache_pool, mode='max'):\n",
    "    A_prev, pool_size, strides = cache_pool\n",
    "    p_H, p_W = pool_size\n",
    "    stride_H, stride_W = strides\n",
    "\n",
    "    m, n_H_prev, n_W_prev, n_C = A_prev.shape\n",
    "    _, n_H, n_W, _ = dA.shape\n",
    "\n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "\n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i, :, :, :]\n",
    "        da_prev = dA_prev[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):\n",
    "            start_H = h * stride_H\n",
    "            end_H = start_H + p_H\n",
    "    \n",
    "            for w in range(n_W):\n",
    "                start_W = w * stride_W\n",
    "                end_W = start_W + p_W\n",
    "    \n",
    "                for c in range(n_C):\n",
    "\n",
    "                    if mode == 'max':\n",
    "                        a_sliced_prev = a_prev[start_H:end_H, start_W:end_W, c]\n",
    "                        mask_maxPool = (a_sliced_prev == np.max(a_sliced_prev)).astype(int)  # mask == dA w.r.t dA_prev\n",
    "                        da_prev[start_H:end_H, start_W:end_W, c] += mask_maxPool * dA[i, h, w, c]\n",
    "                        \n",
    "                    elif mode == 'average':\n",
    "                        mask_avgPool = np.ones(pool_size) / np.prod(pool_size)  # mask == dA w.r.t dA_prev\n",
    "                        da_prev[start_H:end_H, start_W:end_W, c] += mask_avgPool * dA[i, h, w, c]\n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c6ecc2-dee4-4aa7-a975-19274cd36f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 2, 2)\n",
      "(5, 5, 3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14571390272918056,\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [ 5.05844394, -1.68282702],\n",
       "        [ 0.        ,  0.        ]]),\n",
       " array([[ 0.08485462,  0.2787552 ],\n",
       "        [ 1.26461098, -0.25749373],\n",
       "        [ 1.17975636, -0.53624893]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "pool_size = (2,2)\n",
    "strides = (1,1)\n",
    "\n",
    "A, cache_pool = forward_pool(A_prev, pool_size, strides)\n",
    "print(A.shape)\n",
    "print(cache_pool[0].shape)\n",
    "\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "dA_prev_max = backward_pool(dA, cache_pool, mode=\"max\")\n",
    "dA_prev_avg = backward_pool(dA, cache_pool, mode=\"average\")\n",
    "\n",
    "np.mean(dA), dA_prev_max[1, 1], dA_prev_avg[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3fe2c-8121-4d7c-8804-e745bd1e1e1c",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "`mode = max`\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "\n",
    "**mean of dA =**\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "0.145713902729\n",
    "\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>\n",
    "dA_prev[1,1] =\n",
    "</td>\n",
    "<td>\n",
    "[[ 0.          0.        ] <br>\n",
    " [ 5.05844394 -1.68282702] <br>\n",
    " [ 0.          0.        ]]\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "`mode = average`\n",
    "<table> \n",
    "<tr> \n",
    "<td>\n",
    "\n",
    "mean of dA =\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "0.145713902729\n",
    "\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "<td>\n",
    "dA_prev[1,1] =\n",
    "</td>\n",
    "<td>\n",
    "[[ 0.08485462  0.2787552 ] <br>\n",
    " [ 1.26461098 -0.25749373] <br>\n",
    " [ 1.17975636 -0.53624893]]\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9944796-9b5e-4559-a436-4c4366b087ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
